{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "o93JFkaiW0tV",
    "outputId": "deedbddb-e939-48a2-f348-7e954de5ff6f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, AvgPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oKtO_lIPW0tb"
   },
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V_eDq0w4NYxn"
   },
   "source": [
    "## Load Data , test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eqlcQNM8W0tf"
   },
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"../test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "46uBnl5GW0tk",
    "outputId": "1a5a4f6a-deb3-433d-99c0-bd55b0494736"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000,)\n",
      "(70000, 784)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Y_train = train[\"label\"]\n",
    "print(Y_train.shape)\n",
    "\n",
    "X_train = train.drop(labels = [\"label\"],axis = 1) \n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBfMdRl_W0tz"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cqb0xJvnW0t6"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.values.reshape(-1,28,28,1)\n",
    "test = test.values.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fLxERg42W0t_"
   },
   "outputs": [],
   "source": [
    "\n",
    "Y_train = to_categorical(Y_train, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ar_Rv1xjW0uF"
   },
   "outputs": [],
   "source": [
    "\n",
    "random_seed = 46\n",
    "\n",
    "# Test Size Small cause wanna train with all data we have.\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.001, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3jXD103wigGJ",
    "outputId": "72ac7ffc-ca77-40ca-fc5d-e4cb11d2d9e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69860, 28, 28, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KHDZ_pTlNTQB"
   },
   "source": [
    "## Model Construction : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X5KWRaV3W0uQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "input_shape = (28,28,1)\n",
    "def Build_Model(): \n",
    "\n",
    "    model = Sequential()\n",
    "    # 1 conv Layer\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',  activation ='relu', input_shape = input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    # 2 conv Layer\n",
    "    model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AvgPool2D(pool_size=(2,2)))\n",
    "    # 3 #  conv Layer\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    # 4 # First conv Layer\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',  activation ='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(AvgPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256*6, activation = \"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(256*3, activation = \"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(256, activation = \"relu\"))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J-7Qhk2ONPiV"
   },
   "source": [
    "##Â Data augmentation : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eLBYTN1vW0uf"
   },
   "outputs": [],
   "source": [
    "# data augmentation \n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  \t\t\t\n",
    "        samplewise_center=False,  \t\t\t\t\n",
    "        featurewise_std_normalization=False,    \n",
    "        samplewise_std_normalization=False,  \t\n",
    "        zca_whitening=False,  \t\t\t\t\t\n",
    "        rotation_range=10,  \t\t\t\t\t\n",
    "        zoom_range = 0.1, \t\t\t\t\t\t\n",
    "        width_shift_range=0.1,  \t\t\t\t\n",
    "        height_shift_range=0.1,  \t\t\t\t\n",
    "        horizontal_flip=False,  \t\t\t\t\n",
    "        vertical_flip=False)  \t\t\t\t\t\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fpRntOtDNKSy"
   },
   "source": [
    "## Traing off the model : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7UASOzmIju_P"
   },
   "outputs": [],
   "source": [
    "model = Build_Model()\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', patience=3, verbose=1, factor=0.5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-uEDru0-W0uj",
    "outputId": "32ff5725-f33f-40c9-e308-606e5e7568bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "777/777 [==============================] - 33s 43ms/step - loss: 0.1871 - accuracy: 0.9450 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 2/150\n",
      "  5/777 [..............................] - ETA: 26s - loss: 0.1462 - accuracy: 0.9711"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: val_loss,val_accuracy,loss,accuracy,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "777/777 [==============================] - 26s 33ms/step - loss: 0.0830 - accuracy: 0.9781 - val_loss: 0.0350 - val_accuracy: 0.9857\n",
      "Epoch 3/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0652 - accuracy: 0.9832 - val_loss: 0.0267 - val_accuracy: 0.9857\n",
      "Epoch 4/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0559 - accuracy: 0.9856 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
      "Epoch 5/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0518 - accuracy: 0.9872 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 6/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0485 - accuracy: 0.9879 - val_loss: 0.0202 - val_accuracy: 0.9857\n",
      "Epoch 7/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0447 - accuracy: 0.9888 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 8/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0447 - accuracy: 0.9894 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 9/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0398 - accuracy: 0.9903 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 10/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0382 - accuracy: 0.9909 - val_loss: 0.0200 - val_accuracy: 0.9857\n",
      "Epoch 11/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0395 - accuracy: 0.9901 - val_loss: 0.0246 - val_accuracy: 0.9857\n",
      "Epoch 12/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0360 - accuracy: 0.9915 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 13/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0361 - accuracy: 0.9911 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 14/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0362 - accuracy: 0.9915 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 15/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0294 - accuracy: 0.9929 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 16/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0318 - accuracy: 0.9923 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 17/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0317 - accuracy: 0.9926 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 18/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0283 - accuracy: 0.9935 - val_loss: 4.2567e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0269 - accuracy: 0.9933 - val_loss: 7.0954e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0291 - accuracy: 0.9930 - val_loss: 4.9266e-04 - val_accuracy: 1.0000\n",
      "Epoch 21/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0268 - accuracy: 0.9934 - val_loss: 5.1519e-04 - val_accuracy: 1.0000\n",
      "Epoch 22/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0259 - accuracy: 0.9941 - val_loss: 3.1336e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0285 - accuracy: 0.9938 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
      "Epoch 24/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0257 - accuracy: 0.9939 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 25/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0259 - accuracy: 0.9939 - val_loss: 1.5756e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0240 - accuracy: 0.9942 - val_loss: 1.1989e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0259 - accuracy: 0.9944 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0229 - accuracy: 0.9944 - val_loss: 1.0049e-04 - val_accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0260 - accuracy: 0.9937 - val_loss: 3.9708e-04 - val_accuracy: 1.0000\n",
      "Epoch 30/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0239 - accuracy: 0.9945 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0253 - accuracy: 0.9947 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 32/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0249 - accuracy: 0.9944 - val_loss: 1.4152e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0213 - accuracy: 0.9951 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0208 - accuracy: 0.9946 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 35/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0223 - accuracy: 0.9951 - val_loss: 2.5305e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0219 - accuracy: 0.9950 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 37/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0209 - accuracy: 0.9949 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 38/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0236 - accuracy: 0.9947 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 39/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0193 - accuracy: 0.9957 - val_loss: 7.8927e-05 - val_accuracy: 1.0000\n",
      "Epoch 40/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 9.4114e-04 - val_accuracy: 1.0000\n",
      "Epoch 41/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0200 - accuracy: 0.9954 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 42/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0180 - accuracy: 0.9960 - val_loss: 1.9398e-05 - val_accuracy: 1.0000\n",
      "Epoch 43/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0204 - accuracy: 0.9954 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 44/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0235 - accuracy: 0.9948 - val_loss: 4.9283e-04 - val_accuracy: 1.0000\n",
      "Epoch 45/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0204 - accuracy: 0.9953 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 46/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0185 - accuracy: 0.9957 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 47/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0194 - accuracy: 0.9954 - val_loss: 4.1045e-05 - val_accuracy: 1.0000\n",
      "Epoch 48/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 1.8230e-05 - val_accuracy: 1.0000\n",
      "Epoch 49/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0165 - accuracy: 0.9965 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 50/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0197 - accuracy: 0.9957 - val_loss: 7.3329e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0181 - accuracy: 0.9959 - val_loss: 1.7529e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0174 - accuracy: 0.9959 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 53/150\n",
      "777/777 [==============================] - 27s 35ms/step - loss: 0.0170 - accuracy: 0.9962 - val_loss: 6.3223e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0189 - accuracy: 0.9957 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 55/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0169 - accuracy: 0.9959 - val_loss: 6.8235e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/150\n",
      "777/777 [==============================] - 27s 35ms/step - loss: 0.0165 - accuracy: 0.9963 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 57/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0206 - accuracy: 0.9954 - val_loss: 9.1935e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0159 - accuracy: 0.9961 - val_loss: 1.6122e-05 - val_accuracy: 1.0000\n",
      "Epoch 59/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0195 - accuracy: 0.9958 - val_loss: 1.2955e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0176 - accuracy: 0.9959 - val_loss: 3.9132e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0144 - accuracy: 0.9964 - val_loss: 9.0592e-04 - val_accuracy: 1.0000\n",
      "Epoch 62/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0165 - accuracy: 0.9962 - val_loss: 2.0210e-04 - val_accuracy: 1.0000\n",
      "Epoch 63/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0167 - accuracy: 0.9962 - val_loss: 1.5675e-05 - val_accuracy: 1.0000\n",
      "Epoch 64/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0150 - accuracy: 0.9964 - val_loss: 9.7465e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0203 - accuracy: 0.9956 - val_loss: 1.4777e-04 - val_accuracy: 1.0000\n",
      "Epoch 66/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0172 - accuracy: 0.9962 - val_loss: 2.8419e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0173 - accuracy: 0.9961 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 68/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0174 - accuracy: 0.9962 - val_loss: 0.0131 - val_accuracy: 0.9857\n",
      "Epoch 69/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 4.0781e-05 - val_accuracy: 1.0000\n",
      "Epoch 70/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0183 - accuracy: 0.9960 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 71/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0195 - accuracy: 0.9960 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 72/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0148 - accuracy: 0.9966 - val_loss: 6.6108e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0154 - accuracy: 0.9967 - val_loss: 7.9068e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0160 - accuracy: 0.9963 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 75/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 1.9686e-05 - val_accuracy: 1.0000\n",
      "Epoch 76/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0147 - accuracy: 0.9965 - val_loss: 4.6360e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0186 - accuracy: 0.9959 - val_loss: 3.5374e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0142 - accuracy: 0.9968 - val_loss: 3.9797e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0174 - accuracy: 0.9962 - val_loss: 3.8794e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0161 - accuracy: 0.9965 - val_loss: 3.0654e-08 - val_accuracy: 1.0000\n",
      "Epoch 81/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0137 - accuracy: 0.9968 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 82/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 83/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0139 - accuracy: 0.9968 - val_loss: 1.1265e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0131 - accuracy: 0.9971 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 85/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0164 - accuracy: 0.9965 - val_loss: 1.5045e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 1.1427e-04 - val_accuracy: 1.0000\n",
      "Epoch 87/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0148 - accuracy: 0.9970 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 88/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0142 - accuracy: 0.9966 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 89/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0164 - accuracy: 0.9964 - val_loss: 5.2359e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/150\n",
      "777/777 [==============================] - 27s 35ms/step - loss: 0.0155 - accuracy: 0.9966 - val_loss: 7.1047e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0163 - accuracy: 0.9967 - val_loss: 9.0678e-04 - val_accuracy: 1.0000\n",
      "Epoch 92/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 2.3977e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0134 - accuracy: 0.9968 - val_loss: 1.7541e-07 - val_accuracy: 1.0000\n",
      "Epoch 94/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0164 - accuracy: 0.9965 - val_loss: 6.1601e-04 - val_accuracy: 1.0000\n",
      "Epoch 95/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 8.3877e-05 - val_accuracy: 1.0000\n",
      "Epoch 96/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0128 - accuracy: 0.9973 - val_loss: 1.8647e-06 - val_accuracy: 1.0000\n",
      "Epoch 97/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0122 - accuracy: 0.9972 - val_loss: 4.4842e-05 - val_accuracy: 1.0000\n",
      "Epoch 98/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0159 - accuracy: 0.9968 - val_loss: 1.9450e-04 - val_accuracy: 1.0000\n",
      "Epoch 99/150\n",
      "777/777 [==============================] - 27s 34ms/step - loss: 0.0158 - accuracy: 0.9965 - val_loss: 3.6631e-04 - val_accuracy: 1.0000\n",
      "Epoch 100/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0177 - accuracy: 0.9957 - val_loss: 5.0518e-05 - val_accuracy: 1.0000\n",
      "Epoch 101/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0123 - accuracy: 0.9971 - val_loss: 6.7634e-05 - val_accuracy: 1.0000\n",
      "Epoch 102/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 4.2771e-05 - val_accuracy: 1.0000\n",
      "Epoch 103/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 1.1132e-05 - val_accuracy: 1.0000\n",
      "Epoch 104/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0154 - accuracy: 0.9971 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 105/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0142 - accuracy: 0.9966 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 106/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 2.6022e-04 - val_accuracy: 1.0000\n",
      "Epoch 107/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0156 - accuracy: 0.9968 - val_loss: 6.3946e-04 - val_accuracy: 1.0000\n",
      "Epoch 108/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0118 - accuracy: 0.9972 - val_loss: 0.0273 - val_accuracy: 0.9857\n",
      "Epoch 109/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0159 - accuracy: 0.9964 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 110/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 111/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0121 - accuracy: 0.9972 - val_loss: 2.7932e-05 - val_accuracy: 1.0000\n",
      "Epoch 112/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0156 - accuracy: 0.9968 - val_loss: 1.5768e-05 - val_accuracy: 1.0000\n",
      "Epoch 113/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0141 - accuracy: 0.9968 - val_loss: 3.1774e-06 - val_accuracy: 1.0000\n",
      "Epoch 114/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0150 - accuracy: 0.9971 - val_loss: 5.2107e-05 - val_accuracy: 1.0000\n",
      "Epoch 115/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0154 - accuracy: 0.9967 - val_loss: 1.0060e-04 - val_accuracy: 1.0000\n",
      "Epoch 116/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0129 - accuracy: 0.9972 - val_loss: 1.8733e-08 - val_accuracy: 1.0000\n",
      "Epoch 117/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0174 - accuracy: 0.9966 - val_loss: 2.6074e-04 - val_accuracy: 1.0000\n",
      "Epoch 118/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0127 - accuracy: 0.9973 - val_loss: 1.1145e-05 - val_accuracy: 1.0000\n",
      "Epoch 119/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0131 - accuracy: 0.9970 - val_loss: 3.0962e-05 - val_accuracy: 1.0000\n",
      "Epoch 120/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0150 - accuracy: 0.9969 - val_loss: 1.9477e-04 - val_accuracy: 1.0000\n",
      "Epoch 121/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0156 - accuracy: 0.9968 - val_loss: 3.3393e-05 - val_accuracy: 1.0000\n",
      "Epoch 122/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 6.8119e-08 - val_accuracy: 1.0000\n",
      "Epoch 123/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0124 - accuracy: 0.9973 - val_loss: 2.4030e-05 - val_accuracy: 1.0000\n",
      "Epoch 124/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0172 - accuracy: 0.9966 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 125/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0154 - accuracy: 0.9965 - val_loss: 1.8455e-04 - val_accuracy: 1.0000\n",
      "Epoch 126/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0164 - accuracy: 0.9967 - val_loss: 9.7522e-04 - val_accuracy: 1.0000\n",
      "Epoch 127/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0131 - accuracy: 0.9971 - val_loss: 6.7360e-04 - val_accuracy: 1.0000\n",
      "Epoch 128/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 5.4814e-04 - val_accuracy: 1.0000\n",
      "Epoch 129/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0153 - accuracy: 0.9968 - val_loss: 6.5605e-05 - val_accuracy: 1.0000\n",
      "Epoch 130/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0143 - accuracy: 0.9969 - val_loss: 2.1709e-05 - val_accuracy: 1.0000\n",
      "Epoch 131/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0189 - accuracy: 0.9964 - val_loss: 8.2513e-05 - val_accuracy: 1.0000\n",
      "Epoch 132/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0150 - accuracy: 0.9970 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 133/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0140 - accuracy: 0.9971 - val_loss: 5.5483e-04 - val_accuracy: 1.0000\n",
      "Epoch 134/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 135/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0173 - accuracy: 0.9964 - val_loss: 3.2409e-05 - val_accuracy: 1.0000\n",
      "Epoch 136/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0145 - accuracy: 0.9970 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 137/150\n",
      "777/777 [==============================] - 26s 33ms/step - loss: 0.0127 - accuracy: 0.9970 - val_loss: 2.8662e-05 - val_accuracy: 1.0000\n",
      "Epoch 138/150\n",
      "777/777 [==============================] - 26s 33ms/step - loss: 0.0109 - accuracy: 0.9974 - val_loss: 4.7497e-05 - val_accuracy: 1.0000\n",
      "Epoch 139/150\n",
      "777/777 [==============================] - 26s 33ms/step - loss: 0.0143 - accuracy: 0.9970 - val_loss: 5.5970e-06 - val_accuracy: 1.0000\n",
      "Epoch 140/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0169 - accuracy: 0.9966 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 141/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0122 - accuracy: 0.9975 - val_loss: 2.5832e-05 - val_accuracy: 1.0000\n",
      "Epoch 142/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0136 - accuracy: 0.9972 - val_loss: 1.9753e-06 - val_accuracy: 1.0000\n",
      "Epoch 143/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0171 - accuracy: 0.9967 - val_loss: 2.0465e-05 - val_accuracy: 1.0000\n",
      "Epoch 144/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0120 - accuracy: 0.9976 - val_loss: 1.9619e-04 - val_accuracy: 1.0000\n",
      "Epoch 145/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 4.7645e-04 - val_accuracy: 1.0000\n",
      "Epoch 146/150\n",
      "777/777 [==============================] - 26s 33ms/step - loss: 0.0111 - accuracy: 0.9976 - val_loss: 8.4436e-05 - val_accuracy: 1.0000\n",
      "Epoch 147/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0137 - accuracy: 0.9971 - val_loss: 3.3616e-05 - val_accuracy: 1.0000\n",
      "Epoch 148/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0174 - accuracy: 0.9966 - val_loss: 1.1176e-05 - val_accuracy: 1.0000\n",
      "Epoch 149/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0139 - accuracy: 0.9969 - val_loss: 8.2391e-05 - val_accuracy: 1.0000\n",
      "Epoch 150/150\n",
      "777/777 [==============================] - 26s 34ms/step - loss: 0.0140 - accuracy: 0.9965 - val_loss: 0.0040 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "batch_size = 90\n",
    "history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size), epochs = 150, validation_data = (X_val,Y_val),steps_per_epoch=X_train.shape[0] // batch_size, callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "tnRC-HppmJqP",
    "outputId": "4ebf6d63-2937-49e3-b058-e9a1c0183183"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " model saved to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "i=0\n",
    "model_json = model.to_json()\n",
    "with open(\"digits_avgPool_150_epochs.json\", \"w\") as json_file:\n",
    "      json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"digits_avgPool_150_epochs.h5\")\n",
    "print(\" model saved to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "I7a4gSdVW0un",
    "outputId": "89166200-97f8-44a7-fc5a-914d3d7594cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(20,5))\\nplt.subplot(1,2,1 )\\nplt.plot(history.history[\\'loss\\'], color=\\'b\\', label=\"Training loss\")\\nplt.plot(history.history[\\'val_loss\\'], color=\\'r\\', label=\"validation loss\")\\nplt.legend(loc=\\'best\\', shadow=True)\\n\\nplt.subplot(1,2,2 )\\nplt.plot(history.history[\\'accuracy\\'], color=\\'b\\', label=\"Training accuracy\")\\nplt.plot(history.history[\\'val_accuracy\\'], color=\\'r\\',label=\"Validation accuracy\")\\nplt.legend(loc=\\'best\\', shadow=True)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,1 )\n",
    "plt.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "plt.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "\n",
    "plt.subplot(1,2,2 )\n",
    "plt.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "plt.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "plt.legend(loc='best', shadow=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4YZAaDDyNyTD"
   },
   "source": [
    "## prediction and save prediction file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NA9irg-DW0u2"
   },
   "outputs": [],
   "source": [
    "# \n",
    "results = model.predict(test)\n",
    "\n",
    "results = np.argmax(results,axis = 1)\n",
    "results = pd.Series(results,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96Jt0jr2W0u5"
   },
   "outputs": [],
   "source": [
    "# file to save and submit to kaggle.\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "\n",
    "submission.to_csv(\"Predictin_avgPooling_150Epochs.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aMhzpg0vW0vB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Digit_Recognition_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
