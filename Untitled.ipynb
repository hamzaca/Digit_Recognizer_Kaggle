{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('four.png', 0 )\n",
    "\n",
    "img = cv2.imread('gradient.png',0)\n",
    "ret,thresh1 = cv2.threshold(img,60,170,cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[185, 185, 185, ..., 185, 185, 185],\n",
       "       [185, 185, 185, ..., 185, 185, 185],\n",
       "       [185, 185, 185, ..., 185, 185, 185],\n",
       "       ...,\n",
       "       [185, 185, 185, ..., 185, 185, 185],\n",
       "       [185, 185, 185, ..., 185, 185, 185],\n",
       "       [185, 185, 185, ..., 185, 185, 185]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d= Image.fromarray(thresh1)\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('four.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEwAAAA+CAYAAACBff3hAAAFXElEQVR4nO2bX2/SXhiAn1La2pbBZiZMR8iUeLEbE+MH8MbP5KfZF/FOb0x2YfTGuGiiRMk2BnSwAm3p4fC7WOjPv9saT5kjfZIlZLD3PTycvuect0N78eLFnJwrU7juAdw0cmEpyYWlJBeWklxYSnJhKSle9wCyIIoioijiy5cvADx8+BDHcZTEXjlhvu/TbrfpdDrs7e0B8Pz5cxqNBuvr638dX6mwOI6JoggpJUIIKpUKuq6rTHEpURTheR7j8ZiNjQ0ApWNQKmwwGDAYDBBCMJlMePDgQTLoZTEej+l2uwRBwJ07dwAoFtW9TaXCgiDA933iOMb3faIoUhn+SkgpiaKI6XTKdDpNfqcKpcI6nQ6tVoswDOn1ety9e5etrS2VKS4lDEM8zyMIAgaDAQBCCOZzNUdmpcJmsxlCCGazmcqwqRBCIIRASommaQAUCoXk8d+iVNiHDx/Y39/HdV3q9brK0FdiMpnw8eNHXr16hWmaPHnyBIDt7W0lKyRkNMOEECrDXhnP8xiNRslYLMsC/uGiP5/PlRbYNHiex97eHsfHxwAYhkGtVgP+cWGLn+tG07RM9oBKhAkh6PV6dLtdfN+nUFj+EVVKyWg0SrYyt27d4tGjR8ljVSgRNp/PieM4WR2va4b9nFflpZjEVBGk3+/z9u1but0uwNKLfhRFnJ6ecnJyQhiGwLms27dvK8+lbIbNZrNrmVlSSmazWZL/+zFkURqUCJtMJhweHhIEAQC2bdNoNFhbW1MR/kL29/d59+4dw+GQMAzRdZ1yuUytVlNauxYom2FSyh8+XV3Xle2uL0IIQRiGybkRzmeWyt3992TSD3Mch2azSaVSUR671WoxHA7p9/u8f/+ez58/c3h4mCw4zWaTp0+fUi6XM9lWZLL+FwoFisWi8hqyWI3DMCQIAobDIaPR6Iezq2mauK6rrMP6M5nMsEU/LI7jP77G8zzgXMJ0Ok3ayb7vJ0Uczs+n4/EYKSVSSqbTKVJKDMPAdd1fPpS1tTUajUZyLFJNZi3qy1bNxfI/n88JgoBerwecNyHjOE62Jp8+fWIwGCSxdF1H13Vc18V1XTRNQ9O05PlisYjjOJnswUCRME3TkkILcHZ2xps3bzg+PmZzc/OX10dRRLvdBv6/zE5OTpLn5vM5tm0DsLm5SaVSwTRNHMdhY2MDy7KwbZtarcbr1685PT1NFh3TNCmVSpm1xpUIW9Ssxark+z4vX76kXC4nb/x7oiii3+//eVDFYtIe2tnZwXEcyuUyW1tb7OzssL6+jmEYWJbF0dERBwcHaJqGEALbtjPZTiRjUxHk3r17PHv2jFKpxLdv35hOpwyHQwzD+O2lIaVMakyj0cC27WRXXq1WsSwL13UBKJVKFItFTNPEtm1KpRKmaTIej2m1WhwdHSVbCtM0M6tdC5QIsyyLZrPJcDjEdV183+fr168X/s1CyO7uLpVKhe3tbQDu379/pZxSStrtdtKGBjKtXQuURq9Wq+i6ThiGVz7HNRoNHMdJvWeL45h+v//DjZZqtZr56UKpsHq9vrTWdBAEtFotzs7OgPPLcXd3N/ObLivzvxWWZVGv15X17v/EyggzTTNZQbNkZYQti1xYSlZG2KKnn3W3d2WECSEYDAaMx+NM86yMsGWxUsKWcRN55YRlLW1lhAVBwMHBAZ1OJ9M8KyNsWeTCUnKjhWV1K+3CnEvNppByuczjx49/2wLPkhsrTNO0TG7lXZr3pn/BNI5j4jhG0zRM08z8ewE3/psghmFgGMbS8t3YS/K6yIWlJBeWklxYSnJhKcmFpSQXlpJcWEpyYSnJhaUkF5aS/wAR3my4+mLEfwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=76x62 at 0x7F22CE46D160>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- ------------ --------  API START  ----------------------- ------------ ---------\n",
      "----------------- ------------ --------  Model Loaded   ----------------------- ------------ ---------\n",
      "----------------- ------------ --------  image_path  ----------------------- ------------ ---------\n",
      "image_path =  four.png\n",
      "----------------- ------------ --------  Image resized  ----------------------- ------------ ---------\n",
      "shape image :  (28, 28)\n",
      "----------------- ------------ --------  OUt  ----------------------- ------------ ---------\n",
      "out =  [9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Jun  6 03:30:46 2020\n",
    "\n",
    "@author: hamza\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "import pickle\n",
    "from PIL import  Image\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"----------------- ------------ --------  API START  ----------------------- ------------ ---------\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "trained_model_name = \"data/digits_avgPool_150_epochs\"\n",
    "\n",
    "json_file = open(trained_model_name +\".json\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(trained_model_name +\".h5\")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model._make_predict_function()\n",
    "print(\"----------------- ------------ --------  Model Loaded   ----------------------- ------------ ---------\")\n",
    "\n",
    "\n",
    "\n",
    "def addWhitePixelsArround(file,new_size = (28, 28)):\n",
    "    \n",
    "    \"\"\" Add white pixels arround the image to have the shape 28x28, \n",
    "        and resize the image to the same shape if the image shape is bigger than 28x28.\n",
    "    \n",
    "\n",
    "\n",
    "        return :  - image_new : filan image with shape 28x28\n",
    "    \n",
    "    \"\"\"\n",
    "    with Image.open(file).convert('L') as image:\n",
    "        old_size = image.size\n",
    "\n",
    "        if new_size > old_size:\n",
    "                  \n",
    "            # changer le nombres de pixels de sorte d'entendre l'image vers la gauche, la droite et le haut de l'image.\n",
    "            # etendre vers le bas en respectant la parit√© des nombres.\n",
    "    \n",
    "            if old_size[0] % 2 == 0:\n",
    "                    add_left = add_right = (new_size[0] - old_size[0]) // 2\n",
    "            else:\n",
    "                    add_left = (new_size[0] - old_size[0]) // 2\n",
    "                    add_right = ((new_size[0] - old_size[0]) // 2) + 1\n",
    "\n",
    "            if old_size[1] % 2 == 0:\n",
    "                    add_top = add_bottom = (new_size[1] - old_size[1]) // 2\n",
    "            else:\n",
    "                    add_top = (new_size[1] - old_size[1]) // 2\n",
    "                    add_bottom = ((new_size[1] - old_size[1]) // 2) + 1\n",
    "\n",
    "            left = 0 - add_left\n",
    "            top = 0 - add_top\n",
    "            right = old_size[0] + add_right\n",
    "            bottom = old_size[1] + add_bottom\n",
    "                \n",
    "            im_inverse = 255 - np.array(image)\n",
    "            im = Image.fromarray(im_inverse)\n",
    "                \n",
    "            # By default, the added pixels are black\n",
    "            image_new = im.crop((left, top, right, bottom))\n",
    "                \n",
    "            image_new = (255 - np.array(image_new))/255.\n",
    "        #  if the size of the image is bigger than 28x28 so resize it.\n",
    "        else :\n",
    "            image_new = np.array(image.resize((28,28),Image.ANTIALIAS))\n",
    "            \n",
    "        \n",
    "        print(\"----------------- ------------ --------  Image resized  ----------------------- ------------ ---------\")\n",
    "\n",
    "\n",
    "        return image_new\n",
    "\n",
    "\n",
    "\n",
    "def predict():\n",
    "    \n",
    "\n",
    "    path_image = \"four.png\"\n",
    "    print(\"----------------- ------------ --------  image_path  ----------------------- ------------ ---------\")\n",
    "    \n",
    "    print(\"image_path = \", path_image)\n",
    "    \n",
    "    # read image\n",
    "    image =  addWhitePixelsArround(path_image)\n",
    "    print(\"shape image : \", image.shape)\n",
    "    y = model.predict(image.reshape(-1,28, 28 , 1))\n",
    "    output = np.argmax(y, axis = 1)\n",
    "    \n",
    "        \n",
    "    print(\"----------------- ------------ --------  OUt  ----------------------- ------------ ---------\")\n",
    "    \n",
    "    print(\"out = \", output)\n",
    "    \n",
    "    return   output\n",
    "\n",
    "\n",
    "\n",
    "predict()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
